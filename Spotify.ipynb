{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond Wrapped: Spotify Analytics - Phase 1\n",
    "\n",
    "**Course**: IME 565 - Predictive Data Analytics for Engineers  \n",
    "**Team**: Nicolo DiFerdinando, Joe Mascher, Rithvik Shetty  \n",
    "**Phase**: Foundation Analytics\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "1. Load and explore Spotify track datasets\n",
    "2. Perform comprehensive data cleaning and preprocessing\n",
    "3. Analyze audio features and their distributions\n",
    "4. Identify top tracks, artists, and genres\n",
    "5. Create temporal analysis (if timestamp data available)\n",
    "6. Build visualizations for insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Utilities\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "This section auto-detects CSV files in the data directory and loads them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all CSV files in data directory\n",
    "data_dir = Path('data')\n",
    "csv_files = list(data_dir.glob('*.csv'))\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files in data directory:\")\n",
    "for i, file in enumerate(csv_files, 1):\n",
    "    file_size = file.stat().st_size / (1024 * 1024)\n",
    "    print(f\"  {i}. {file.name} ({file_size:.2f} MB)\")\n",
    "\n",
    "# Load the first CSV file\n",
    "if csv_files:\n",
    "    selected_file = csv_files[0]\n",
    "    print(f\"\\nLoading: {selected_file.name}...\")\n",
    "    \n",
    "    df = pd.read_csv(selected_file)\n",
    "    print(f\"Loaded {len(df):,} rows and {len(df.columns)} columns\")\n",
    "else:\n",
    "    print(\"\\nNo CSV files found in data/ directory!\")\n",
    "    print(\"Please download datasets from Kaggle (see data/README.md)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"Dataset Preview:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\" * 50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Understanding and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Basic Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing.index,\n",
    "    'Missing Count': missing.values,\n",
    "    'Percentage': missing_pct.values\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "missing_df[missing_df['Missing Count'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify audio feature columns\n",
    "audio_features = ['danceability', 'energy', 'loudness', 'speechiness', \n",
    "                  'acousticness', 'instrumentalness', 'liveness', 'valence', \n",
    "                  'tempo', 'duration_ms', 'key', 'mode', 'time_signature']\n",
    "\n",
    "# Find which audio features exist in this dataset\n",
    "available_features = [col for col in audio_features if col in df.columns]\n",
    "\n",
    "print(f\"Available Audio Features ({len(available_features)}):\")\n",
    "for feature in available_features:\n",
    "    print(f\"  - {feature}\")\n",
    "\n",
    "if available_features:\n",
    "    print(f\"\\nFound {len(available_features)} audio features to analyze\")\n",
    "else:\n",
    "    print(\"\\nNo standard audio features found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(f\"Original dataset: {len(df_clean):,} rows\")\n",
    "\n",
    "# Remove duplicates\n",
    "initial_count = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "duplicates_removed = initial_count - len(df_clean)\n",
    "print(f\"Removed {duplicates_removed:,} duplicate rows\")\n",
    "\n",
    "# Handle missing values in audio features\n",
    "if available_features:\n",
    "    initial_count = len(df_clean)\n",
    "    df_clean = df_clean.dropna(subset=available_features)\n",
    "    missing_removed = initial_count - len(df_clean)\n",
    "    print(f\"Removed {missing_removed:,} rows with missing audio features\")\n",
    "\n",
    "# Remove invalid loudness values (should be negative dB)\n",
    "if 'loudness' in df_clean.columns:\n",
    "    initial_count = len(df_clean)\n",
    "    df_clean = df_clean[df_clean['loudness'] <= 0]\n",
    "    invalid_removed = initial_count - len(df_clean)\n",
    "    print(f\"Removed {invalid_removed:,} rows with invalid loudness values\")\n",
    "\n",
    "# Remove extremely short durations\n",
    "if 'duration_ms' in df_clean.columns:\n",
    "    initial_count = len(df_clean)\n",
    "    df_clean = df_clean[df_clean['duration_ms'] >= 5000]\n",
    "    short_removed = initial_count - len(df_clean)\n",
    "    print(f\"Removed {short_removed:,} rows with duration < 5 seconds\")\n",
    "\n",
    "print(f\"\\nFinal cleaned dataset: {len(df_clean):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Audio Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of audio features\n",
    "if available_features:\n",
    "    normalized_features = [f for f in available_features \n",
    "                          if f not in ['loudness', 'tempo', 'duration_ms', 'key', 'mode', 'time_signature']]\n",
    "    \n",
    "    if normalized_features:\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for idx, feature in enumerate(normalized_features[:9]):\n",
    "            axes[idx].hist(df_clean[feature].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "            axes[idx].set_title(f'{feature.capitalize()} Distribution', fontsize=12, fontweight='bold')\n",
    "            axes[idx].set_xlabel(feature.capitalize())\n",
    "            axes[idx].set_ylabel('Frequency')\n",
    "            axes[idx].grid(True, alpha=0.3)\n",
    "            \n",
    "            mean_val = df_clean[feature].mean()\n",
    "            axes[idx].axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.3f}')\n",
    "            axes[idx].legend()\n",
    "        \n",
    "        for idx in range(len(normalized_features), 9):\n",
    "            axes[idx].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('Audio Feature Distributions', fontsize=16, fontweight='bold', y=1.001)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix of audio features\n",
    "if len(available_features) > 1:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation_matrix = df_clean[available_features].corr()\n",
    "    \n",
    "    sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "    \n",
    "    plt.title('Audio Features Correlation Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering: Composite Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create composite features\n",
    "\n",
    "# Mood Score\n",
    "if all(col in df_clean.columns for col in ['valence', 'energy', 'acousticness']):\n",
    "    df_clean['mood_score'] = (\n",
    "        0.5 * df_clean['valence'] + \n",
    "        0.3 * df_clean['energy'] + \n",
    "        0.2 * (1 - df_clean['acousticness'])\n",
    "    )\n",
    "    print(\"Created 'mood_score'\")\n",
    "\n",
    "# Grooviness Index\n",
    "if all(col in df_clean.columns for col in ['danceability', 'energy', 'tempo']):\n",
    "    tempo_normalized = (df_clean['tempo'] - df_clean['tempo'].min()) / (df_clean['tempo'].max() - df_clean['tempo'].min())\n",
    "    df_clean['grooviness'] = (\n",
    "        0.4 * df_clean['danceability'] + \n",
    "        0.3 * df_clean['energy'] + \n",
    "        0.3 * tempo_normalized\n",
    "    )\n",
    "    print(\"Created 'grooviness'\")\n",
    "\n",
    "# Focus Score\n",
    "if all(col in df_clean.columns for col in ['speechiness', 'energy', 'instrumentalness']):\n",
    "    df_clean['focus_score'] = (\n",
    "        0.4 * (1 - df_clean['speechiness']) + \n",
    "        0.3 * df_clean['instrumentalness'] + \n",
    "        0.3 * (1 - abs(df_clean['energy'] - 0.5) * 2)\n",
    "    )\n",
    "    print(\"Created 'focus_score'\")\n",
    "\n",
    "# Relaxation Score\n",
    "if all(col in df_clean.columns for col in ['energy', 'acousticness', 'tempo']):\n",
    "    tempo_normalized = (df_clean['tempo'] - df_clean['tempo'].min()) / (df_clean['tempo'].max() - df_clean['tempo'].min())\n",
    "    df_clean['relaxation_score'] = (\n",
    "        0.4 * (1 - df_clean['energy']) + \n",
    "        0.3 * df_clean['acousticness'] + \n",
    "        0.3 * (1 - tempo_normalized)\n",
    "    )\n",
    "    print(\"Created 'relaxation_score'\")\n",
    "\n",
    "print(\"\\nComposite features created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Top Tracks, Artists, and Genres Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify column names\n",
    "track_col = None\n",
    "artist_col = None\n",
    "genre_col = None\n",
    "popularity_col = None\n",
    "\n",
    "for col in df_clean.columns:\n",
    "    col_lower = col.lower()\n",
    "    if 'track' in col_lower and 'name' in col_lower:\n",
    "        track_col = col\n",
    "    elif 'artist' in col_lower and ('name' in col_lower or col_lower == 'artists'):\n",
    "        artist_col = col\n",
    "    elif 'genre' in col_lower:\n",
    "        genre_col = col\n",
    "    elif 'popular' in col_lower:\n",
    "        popularity_col = col\n",
    "\n",
    "print(\"Identified columns:\")\n",
    "print(f\"  Track: {track_col}\")\n",
    "print(f\"  Artist: {artist_col}\")\n",
    "print(f\"  Genre: {genre_col}\")\n",
    "print(f\"  Popularity: {popularity_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Artists\n",
    "if artist_col:\n",
    "    print(\"Top 20 Artists:\")\n",
    "    print(\"=\" * 50)\n",
    "    top_artists = df_clean[artist_col].value_counts().head(20)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_artists.plot(kind='barh', color='skyblue', edgecolor='black')\n",
    "    plt.xlabel('Number of Tracks', fontsize=12)\n",
    "    plt.ylabel('Artist', fontsize=12)\n",
    "    plt.title('Top 20 Artists by Track Count', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(top_artists)\n",
    "else:\n",
    "    print(\"Artist column not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Genres\n",
    "if genre_col:\n",
    "    print(\"Top 20 Genres:\")\n",
    "    print(\"=\" * 50)\n",
    "    top_genres = df_clean[genre_col].value_counts().head(20)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_genres.plot(kind='bar', color='lightcoral', edgecolor='black')\n",
    "    plt.xlabel('Genre', fontsize=12)\n",
    "    plt.ylabel('Number of Tracks', fontsize=12)\n",
    "    plt.title('Top 20 Genres by Track Count', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(top_genres)\n",
    "else:\n",
    "    print(\"Genre column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Context Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule-based context classification\n",
    "def classify_context(row):\n",
    "    if row.get('energy', 0) > 0.7 and row.get('danceability', 0) > 0.6:\n",
    "        return 'Workout'\n",
    "    if row.get('speechiness', 0) < 0.2 and row.get('instrumentalness', 0) > 0.5:\n",
    "        return 'Focus'\n",
    "    if row.get('energy', 0) < 0.4 and row.get('acousticness', 0) > 0.5:\n",
    "        return 'Relaxation'\n",
    "    if row.get('valence', 0) > 0.6 and row.get('energy', 0) > 0.6 and row.get('danceability', 0) > 0.6:\n",
    "        return 'Party'\n",
    "    return 'General'\n",
    "\n",
    "if available_features:\n",
    "    df_clean['context'] = df_clean.apply(classify_context, axis=1)\n",
    "    \n",
    "    print(\"Context Classification Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    context_counts = df_clean['context'].value_counts()\n",
    "    print(context_counts)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    context_counts.plot(kind='bar', color='teal', edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel('Context', fontsize=12)\n",
    "    plt.ylabel('Number of Tracks', fontsize=12)\n",
    "    plt.title('Track Distribution by Listening Context', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset\n",
    "output_path = Path('data/processed_spotify_data.csv')\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Processed data saved to: {output_path}\")\n",
    "print(f\"  Rows: {len(df_clean):,}\")\n",
    "print(f\"  Columns: {len(df_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"PHASE 1 ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"  Total tracks analyzed: {len(df_clean):,}\")\n",
    "print(f\"  Total features: {len(df_clean.columns)}\")\n",
    "print(f\"  Audio features: {len(available_features)}\")\n",
    "\n",
    "if artist_col:\n",
    "    print(f\"\\nArtists:\")\n",
    "    print(f\"  Unique artists: {df_clean[artist_col].nunique():,}\")\n",
    "\n",
    "if genre_col:\n",
    "    print(f\"\\nGenres:\")\n",
    "    print(f\"  Unique genres: {df_clean[genre_col].nunique():,}\")\n",
    "\n",
    "if 'energy' in df_clean.columns:\n",
    "    print(f\"\\nAudio Characteristics:\")\n",
    "    print(f\"  Average energy: {df_clean['energy'].mean():.3f}\")\n",
    "    if 'valence' in df_clean.columns:\n",
    "        print(f\"  Average valence: {df_clean['valence'].mean():.3f}\")\n",
    "    if 'danceability' in df_clean.columns:\n",
    "        print(f\"  Average danceability: {df_clean['danceability'].mean():.3f}\")\n",
    "\n",
    "print(f\"\\nPhase 1 Analysis Complete!\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
